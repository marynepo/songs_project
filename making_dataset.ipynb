{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lyricsgenius\n",
    "#!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "B9ZnF95R0S1C"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from lyricsgenius import Genius\n",
    "from tqdm import tqdm\n",
    "import sqlite3\n",
    "from langdetect import detect\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "conn = sqlite3.connect('songs.db')\n",
    "c = conn.cursor()\n",
    "genius = Genius('0NRl7k3ZzZXDaHFTkE882V0DP8nKbra_WoufZhtBjTngOjTxIa80_6u3W48RjIvt', skip_non_songs=True, excluded_terms=[\"(Remix)\", \"(Live)\"], timeout=15, retries=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"CREATE TABLE Songs ('title', 'artists', 'featured artists', 'genre', 'lyrics')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BWZLny395gZw"
   },
   "outputs": [],
   "source": [
    "def get_genre_lyrics(genre):\n",
    "    page = 1\n",
    "    for _ in tqdm(range(50)):\n",
    "        res = genius.tag(genre, page=page)\n",
    "        for hit in res['hits']:\n",
    "            song_lyrics = genius.lyrics(song_url=hit['url'])\n",
    "            artists =  ' '.join(hit['artists'])\n",
    "            featured_artists = ' '.join(hit['featured_artists'])\n",
    "            c.execute('INSERT INTO Songs VALUES (?, ?, ?, ?, ?)', \n",
    "                      (hit['title'], artists, featured_artists,\n",
    "                       genre, song_lyrics))\n",
    "        page = res['next_page']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "f-fXZJar9oOa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [33:06<00:00, 39.73s/it]\n",
      "100%|██████████| 50/50 [31:12<00:00, 37.45s/it]\n",
      "100%|██████████| 50/50 [32:35<00:00, 39.12s/it]\n",
      "100%|██████████| 50/50 [34:46<00:00, 41.72s/it]\n",
      "100%|██████████| 50/50 [34:08<00:00, 40.97s/it]\n"
     ]
    }
   ],
   "source": [
    "genres = ['pop', 'rap', 'rock', 'folk', 'indie']\n",
    "for genre in genres:\n",
    "    get_genre_lyrics(genre)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "import spacy\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4999it [03:01, 27.57it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql('SELECT * FROM Songs', conn)\n",
    "nonen = []\n",
    "choruses = []\n",
    "verses = []\n",
    "songs = []\n",
    "fulls = []\n",
    "fullcs = []\n",
    "fullvs = []\n",
    "for n, song in tqdm(enumerate(df.lyrics)):\n",
    "    lan = detect(song)\n",
    "    if lan != 'en':\n",
    "        nonen.append(n)\n",
    "    else:\n",
    "        chorus = ''\n",
    "        verse = ''\n",
    "        sg = ''\n",
    "        full_c = []\n",
    "        full_v = []\n",
    "        part_types = re.findall('\\[.+\\]', song)\n",
    "        parts = re.split('\\[.+\\]', song)\n",
    "        full_s = '\\n'.join(parts)\n",
    "        for i, part_type in enumerate(part_types):\n",
    "            doc = nlp(parts[i+1])\n",
    "            part = ' '.join([token.lemma_ for token in doc])\n",
    "            if '[Chorus' in part_type:\n",
    "                chorus += part\n",
    "                full_c += parts[i+1]\n",
    "            else:\n",
    "                verse += part\n",
    "                full_v += parts[i+1]\n",
    "            sg += part\n",
    "        choruses.append(chorus)\n",
    "        verses.append(verse)\n",
    "        songs.append(sg)\n",
    "        fulls.append(full_s)\n",
    "        fullcs.append(''.join(full_c))\n",
    "        fullvs.append(''.join(full_v))\n",
    "        \n",
    "df = df.drop(nonen)\n",
    "df['clean_chorus'] = choruses\n",
    "df['clean_verses'] = verses\n",
    "df['clean_lyrics'] = songs\n",
    "df['full_lyrics'] = fulls\n",
    "df['full_chorus'] = fullcs\n",
    "df['full_verses'] = fullvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[(df.clean_chorus == '') | (df.clean_verses == '')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pop 870\n",
      "rap 777\n",
      "rock 859\n",
      "folk 634\n",
      "indie 795\n"
     ]
    }
   ],
   "source": [
    "genres = ['pop', 'rap', 'rock', 'folk', 'indie']\n",
    "for genre in genres:\n",
    "    print(genre, len(df[df.genre==genre]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThank you, next (Next)\\nThank you, next (Next)\\nThank you, next\\nI'm so fuckin' grateful for my ex\\nThank you, next (Next)\\nThank you, next (Next)\\nThank you, next (Next)\\nI'm so fuckin'—\\n\\nThank you, next (Thank you, next)\\nThank you, next (Thank you, next)\\nThank you, next (Thank you)\\nI'm so fuckin' grateful for my ex\\nThank you, next (Thank you, next)\\nThank you, next (Said thank you, next)\\nThank you, next (Next)\\nI'm so fuckin' grateful for my ex\\n\\nThank you, next (Thank you, next)\\nThank you, next (Thank you, next)\\nThank you, next\\nI'm so fuckin' grateful for my ex\\nThank you, next (Thank you, next)\\nThank you, next (Said thank you, next)\\nThank you, next (Next)\\nI'm so fuckin' grateful for my ex\\n\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.full_chorus.values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql('Splitted', conn)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('SELECT * FROM Splitted', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "waste = ['-pron-', 'ya', 'e', 'hey', 'oh', 'la', 'uh', 'ayy', 'ooh', 'ah', 'da', 'mmm', 'ba', 'doo', 'woah', 'whoa', 'na', 'oo+h*', 'o', '-', 'm', 's', '\\W+', 'hoh', 'yeah', 'yee']\n",
    "def make_corpus(texts, filename):\n",
    "    doc = ''\n",
    "    for i, text in enumerate(texts):\n",
    "        text = text.lower()\n",
    "        song = re.sub('[^\\w-]', ' ', text)\n",
    "        song = re.sub(' +', ' ', song)\n",
    "        clean_lr = []\n",
    "        for word in song.split():\n",
    "            lexeme = nlp.vocab[word]\n",
    "            if lexeme.is_stop == False and word not in waste:\n",
    "                clean_lr.append(word)\n",
    "        song = ' '.join(clean_lr)\n",
    "        doc += ('doc' + str(i) + ' ' + song.lower() + ' | genre ' + df.genre.values[i] + '\\n')\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(doc)\n",
    "    return doc, song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_doc = make_corpus(df.clean_lyrics, 'full_corpus.txt')\n",
    "ch_doc = make_corpus(df.clean_chorus, 'ch_corpus.txt')\n",
    "v_doc = make_corpus(df.clean_lyrics, 'v_corpus.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
